# Database Migration Plan

## ðŸŽ¯ Current Issues with In-Memory Storage

### Problems:
- **Stale Data**: Data resets when server restarts
- **No Persistence**: All data lost on crashes
- **Race Conditions**: Multiple requests can cause data inconsistency
- **No Transactions**: Can't ensure data integrity
- **Scalability**: Won't work with multiple server instances

### Benefits of Real Database:
- âœ… **Persistent Data**: Survives server restarts
- âœ… **Data Integrity**: ACID transactions
- âœ… **Concurrent Access**: Proper locking and isolation
- âœ… **Scalability**: Can handle multiple users
- âœ… **Backup/Recovery**: Data safety
- âœ… **Query Performance**: Indexed searches

## ðŸ› ï¸ Implementation Options

### Option 1: SQLite (Recommended for Development)
**Pros:**
- No setup required
- File-based database
- Perfect for development/testing
- Easy to backup/restore

**Cons:**
- Single-writer limitation
- Not ideal for high concurrency

### Option 2: PostgreSQL (Recommended for Production)
**Pros:**
- Full-featured database
- Excellent concurrency
- JSON support for complex data
- Production-ready

**Cons:**
- Requires setup/installation
- More complex configuration

## ðŸš€ Quick Implementation Plan

### Phase 1: SQLite Integration (2-3 hours)
1. **Add SQLAlchemy ORM** - Database abstraction layer
2. **Create Database Models** - Convert Pydantic models to SQLAlchemy
3. **Database Operations** - Replace in-memory operations
4. **Migration Script** - Convert existing data
5. **Testing** - Verify all functionality works

### Phase 2: PostgreSQL Option (1-2 hours)
1. **Docker Setup** - Easy PostgreSQL deployment
2. **Configuration** - Environment-based database selection
3. **Production Ready** - Connection pooling, etc.

## ðŸ“‹ Implementation Steps

### Step 1: Add Dependencies
```bash
cd hotel-onboarding-backend
poetry add sqlalchemy alembic sqlite3
```

### Step 2: Create Database Models
```python
# app/database.py
from sqlalchemy import create_engine, Column, String, DateTime, Boolean, Text, Float
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker

Base = declarative_base()

class User(Base):
    __tablename__ = "users"
    id = Column(String, primary_key=True)
    email = Column(String, unique=True, index=True)
    first_name = Column(String)
    last_name = Column(String)
    role = Column(String)
    property_id = Column(String, nullable=True)
    is_active = Column(Boolean, default=True)
    created_at = Column(DateTime)
    updated_at = Column(DateTime)

class Property(Base):
    __tablename__ = "properties"
    id = Column(String, primary_key=True)
    name = Column(String)
    address = Column(String)
    city = Column(String)
    state = Column(String)
    zip_code = Column(String)
    phone = Column(String)
    qr_code_url = Column(Text)
    is_active = Column(Boolean, default=True)
    created_at = Column(DateTime)

class JobApplication(Base):
    __tablename__ = "job_applications"
    id = Column(String, primary_key=True)
    property_id = Column(String)
    department = Column(String)
    position = Column(String)
    applicant_data = Column(Text)  # JSON
    status = Column(String)
    applied_at = Column(DateTime)
    reviewed_at = Column(DateTime, nullable=True)
    reviewed_by = Column(String, nullable=True)
    rejection_reason = Column(Text, nullable=True)
    talent_pool_date = Column(DateTime, nullable=True)
```

### Step 3: Database Service Layer
```python
# app/database_service.py
from sqlalchemy.orm import Session
from typing import List, Optional
import json

class DatabaseService:
    def __init__(self, db: Session):
        self.db = db
    
    def create_application(self, application_data: dict) -> JobApplication:
        db_application = JobApplication(
            id=application_data["id"],
            property_id=application_data["property_id"],
            department=application_data["department"],
            position=application_data["position"],
            applicant_data=json.dumps(application_data["applicant_data"]),
            status=application_data["status"],
            applied_at=application_data["applied_at"]
        )
        self.db.add(db_application)
        self.db.commit()
        return db_application
    
    def get_applications_by_property(self, property_id: str) -> List[JobApplication]:
        return self.db.query(JobApplication).filter(
            JobApplication.property_id == property_id
        ).all()
    
    def update_application_status(self, app_id: str, status: str, **kwargs):
        application = self.db.query(JobApplication).filter(
            JobApplication.id == app_id
        ).first()
        if application:
            application.status = status
            for key, value in kwargs.items():
                setattr(application, key, value)
            self.db.commit()
        return application
```

## âš¡ Quick Start Implementation

I can implement this in about 2-3 hours with these steps:

1. **Setup SQLite Database** (30 minutes)
2. **Create Models & Migrations** (45 minutes)
3. **Replace In-Memory Operations** (60 minutes)
4. **Test & Debug** (30 minutes)
5. **Data Migration Script** (15 minutes)

## ðŸŽ¯ Immediate Benefits

After implementation:
- âœ… **No More Stale Data** - All data persists
- âœ… **Consistent State** - Database ensures integrity
- âœ… **Better Performance** - Indexed queries
- âœ… **Easier Debugging** - Can inspect database directly
- âœ… **Production Ready** - Real database backend

## ðŸ“Š Effort vs Impact

**Effort**: 2-3 hours
**Impact**: ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ (Massive improvement)

**This is definitely worth doing!** It will solve:
- All stale data issues
- Race conditions
- Data persistence problems
- Make the system production-ready

Would you like me to implement this? I can start with SQLite (no setup required) and have it working in a few hours.